{
  "api_endpoints": {
    "/llm/llamacpp/health": {
      "status": "FAIL",
      "status_code": 401,
      "method": "GET"
    },
    "/llm/llamacpp/models": {
      "status": "FAIL",
      "status_code": 401,
      "method": "GET"
    },
    "/llm/llamacpp/chat": {
      "status": "FAIL",
      "status_code": 401,
      "method": "POST"
    },
    "/llm/llamacpp/achat": {
      "status": "FAIL",
      "status_code": 401,
      "method": "POST"
    },
    "/llm/llamacpp/embedding": {
      "status": "FAIL",
      "status_code": 401,
      "method": "POST"
    },
    "/llm/llamacpp/switch": {
      "status": "FAIL",
      "status_code": 401,
      "method": "POST"
    }
  },
  "backward_compatibility": {
    "/llm/ollama/health": {
      "status": "FAIL",
      "status_code": 401
    },
    "/llm/ollama/models": {
      "status": "FAIL",
      "status_code": 401
    },
    "/llm/ollama/chat": {
      "status": "FAIL",
      "status_code": 401
    }
  },
  "configuration": {
    "default_provider": {
      "status": "PASS",
      "found": "llamacpp default"
    },
    "fallback_hierarchy": {
      "status": "PASS",
      "found": "llamacpp in fallback docs"
    },
    "environment_variables": {
      "status": "PASS",
      "found_vars": [
        "LLAMACPP_MODEL_NAME",
        "LLAMACPP_CTX_SIZE",
        "LLAMACPP_THREADS"
      ]
    }
  },
  "logging_metrics": {
    "logger_names": {
      "status": "PASS",
      "files_with_llamacpp_loggers": [
        "src/marketplace/ai/llm-services/llama/llama_client.py",
        "plugin_marketplace/ai/llm-services/llama/llama_plugin.py"
      ]
    },
    "metric_names": {
      "status": "PASS",
      "found_metrics": [
        "llamacpp_requests_total",
        "llamacpp_latency_seconds",
        "llamacpp_errors_total",
        "llamacpp_inflight_requests"
      ]
    },
    "log_messages": {
      "status": "PASS",
      "found": "llamacpp_inprocess in log messages"
    }
  },
  "overall_status": "FAIL"
}