"""
Integration test for Progressive Response Streaming System

This test demonstrates the complete functionality of the progressive response streaming system
including all the required features from the task specification.
"""

import asyncio
import sys
import os
from datetime import datetime

# Add the src directory to the path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# Import directly to avoid dependency issues
from test_progressive_streaming_isolated import (
    ProgressiveResponseStreamer,
    ContentSection,
    Priority,
    ContentType,
    FormatType,
    ExpertiseLevel,
    StreamingFeedback,
    ChunkType
)


async def demonstrate_all_features():
    """Demonstrate all features required by the task specification"""
    print("Progressive Response Streaming System - Integration Test")
    print("=" * 60)
    
    # Feature 1: Priority-based content ordering
    print("\n1. Testing Priority-based Content Ordering")
    print("-" * 40)
    
    feedback_messages = []
    
    async def feedback_handler(feedback: StreamingFeedback):
        feedback_messages.append(feedback)
        print(f"   üì¢ Feedback: {feedback.message}")
    
    streamer = ProgressiveResponseStreamer(
        buffer_size=1024,
        chunk_size=256,
        feedback_callback=feedback_handler
    )
    
    # Create content with different priorities
    mixed_priority_content = [
        ContentSection(
            content="Low priority background information that can wait.",
            content_type=ContentType.TEXT,
            priority=Priority.LOW,
            relevance_score=0.3,
            expertise_level=ExpertiseLevel.INTERMEDIATE,
            format_type=FormatType.PLAIN_TEXT,
            is_actionable=False,
            estimated_read_time=8.0
        ),
        ContentSection(
            content="üö® CRITICAL: System security breach detected! Take immediate action!",
            content_type=ContentType.TEXT,
            priority=Priority.CRITICAL,
            relevance_score=1.0,
            expertise_level=ExpertiseLevel.INTERMEDIATE,
            format_type=FormatType.PLAIN_TEXT,
            is_actionable=True,
            estimated_read_time=3.0
        ),
        ContentSection(
            content="High priority: Update your password and enable 2FA",
            content_type=ContentType.TEXT,
            priority=Priority.HIGH,
            relevance_score=0.9,
            expertise_level=ExpertiseLevel.BEGINNER,
            format_type=FormatType.PLAIN_TEXT,
            is_actionable=True,
            estimated_read_time=5.0
        ),
        ContentSection(
            content="Medium priority: Review security logs when convenient",
            content_type=ContentType.TEXT,
            priority=Priority.MEDIUM,
            relevance_score=0.6,
            expertise_level=ExpertiseLevel.ADVANCED,
            format_type=FormatType.PLAIN_TEXT,
            is_actionable=False,
            estimated_read_time=10.0
        )
    ]
    
    chunks = []
    async for chunk in streamer.stream_priority_content(mixed_priority_content):
        chunks.append(chunk)
        if chunk.chunk_type == ChunkType.CONTENT:
            priority_emoji = {
                Priority.CRITICAL: "üî¥",
                Priority.HIGH: "üü†",
                Priority.MEDIUM: "üü°",
                Priority.LOW: "üü¢"
            }.get(chunk.priority, "‚ö™")
            
            print(f"   {priority_emoji} {chunk.priority.name}: {chunk.content[:50]}...")
    
    content_chunks = [c for c in chunks if c.chunk_type == ChunkType.CONTENT]
    print(f"   ‚úÖ Streamed {len(content_chunks)} content chunks in priority order")
    
    # Verify priority ordering
    priorities = [c.priority for c in content_chunks]
    expected_order = [Priority.CRITICAL, Priority.HIGH, Priority.MEDIUM, Priority.LOW]
    assert priorities == expected_order, f"Expected {expected_order}, got {priorities}"
    print("   ‚úÖ Priority ordering verified!")
    
    # Feature 2: Actionable items delivered first
    print("\n2. Testing Actionable Items Delivered First")
    print("-" * 40)
    
    actionable_content = []
    async for content in streamer.deliver_actionable_items_first(mixed_priority_content):
        actionable_content.append(content)
        is_actionable = any(indicator in content for indicator in ["Action Required", "Action Items", "```"])
        marker = "‚ö° ACTIONABLE" if is_actionable else "üìñ EXPLANATORY"
        print(f"   {marker}: {content.strip()[:60]}...")
    
    # Verify actionable items come first
    actionable_indicators = ["Action Required", "Action Items", "```"]
    first_two_actionable = all(
        any(indicator in item for indicator in actionable_indicators)
        for item in actionable_content[:2]
    )
    print(f"   ‚úÖ First two items are actionable: {first_two_actionable}")
    
    # Feature 3: Coherent structure maintenance
    print("\n3. Testing Coherent Structure Maintenance")
    print("-" * 40)
    
    async def fragmented_content():
        fragments = [
            "This is the beginning",
            "of a complex explanation",
            "that spans multiple",
            "fragments and needs\n\n",
            "proper coherence",
            "## New Section\n",
            "Additional information",
            "with proper structure."
        ]
        for fragment in fragments:
            yield fragment
            await asyncio.sleep(0.01)
    
    coherent_items = []
    async for item in streamer.maintain_response_coherence(fragmented_content()):
        coherent_items.append(item)
        print(f"   üìù Coherent: {repr(item)}")
    
    print(f"   ‚úÖ Maintained coherence across {len(coherent_items)} items")
    
    # Feature 4: Real-time feedback system
    print("\n4. Testing Real-time Feedback System")
    print("-" * 40)
    
    print(f"   üìä Total feedback messages received: {len(feedback_messages)}")
    for i, feedback in enumerate(feedback_messages[:3]):  # Show first 3
        print(f"   {i+1}. [{feedback.feedback_type.upper()}] {feedback.message}")
    
    if len(feedback_messages) > 3:
        print(f"   ... and {len(feedback_messages) - 3} more messages")
    
    print("   ‚úÖ Real-time feedback system working!")
    
    # Feature 5: Streaming error handling and recovery
    print("\n5. Testing Streaming Error Handling and Recovery")
    print("-" * 40)
    
    test_errors = [
        (asyncio.TimeoutError("Connection timeout"), "retry_with_timeout"),
        (ConnectionError("Network lost"), "reconnect_and_retry"),
        (MemoryError("Out of memory"), "reduce_chunk_size"),
        (ValueError("Invalid data"), "fallback_to_simple_delivery")
    ]
    
    for error, expected_strategy in test_errors:
        error_chunk = await streamer.handle_streaming_errors("test_stream", error)
        actual_strategy = error_chunk.metadata.get("recovery_strategy")
        
        print(f"   üîß {type(error).__name__}: {actual_strategy}")
        assert actual_strategy == expected_strategy, f"Expected {expected_strategy}, got {actual_strategy}"
    
    print("   ‚úÖ Error handling and recovery mechanisms working!")
    
    # Feature 6: Response chunking and buffering optimization
    print("\n6. Testing Response Chunking and Buffering Optimization")
    print("-" * 40)
    
    large_content = """
This is a comprehensive guide to system security that contains multiple sections and detailed information.

## Introduction
Security is paramount in modern systems. This guide covers essential practices and procedures.

## Authentication
Strong authentication mechanisms include:
- Multi-factor authentication (MFA)
- Strong password policies
- Regular password rotation
- Account lockout policies

## Code Example
```python
def secure_login(username, password, mfa_token):
    if not validate_credentials(username, password):
        return False
    if not verify_mfa_token(mfa_token):
        return False
    return create_secure_session(username)
```

## Network Security
Network security involves multiple layers of protection including firewalls, intrusion detection systems, and encrypted communications.

## Conclusion
Implementing comprehensive security requires ongoing vigilance and regular updates to security policies and procedures.
"""
    
    # Test different chunk sizes
    for chunk_size in [100, 200, 400]:
        chunks = await streamer.optimize_response_chunking(large_content, target_chunk_size=chunk_size)
        print(f"   üì¶ Chunk size {chunk_size}: {len(chunks)} chunks created")
        
        # Verify chunks are appropriately sized
        for i, chunk in enumerate(chunks):
            if len(chunk) > chunk_size * 1.5:  # Allow some flexibility
                print(f"      ‚ö†Ô∏è  Chunk {i+1} is large: {len(chunk)} chars")
            else:
                print(f"      ‚úÖ Chunk {i+1}: {len(chunk)} chars")
    
    print("   ‚úÖ Response chunking optimization working!")
    
    # Summary
    print("\n" + "=" * 60)
    print("INTEGRATION TEST SUMMARY")
    print("=" * 60)
    
    features_tested = [
        "‚úÖ Priority-based content ordering",
        "‚úÖ Actionable items delivered first", 
        "‚úÖ Coherent structure maintenance",
        "‚úÖ Real-time feedback system",
        "‚úÖ Streaming error handling and recovery",
        "‚úÖ Response chunking and buffering optimization"
    ]
    
    for feature in features_tested:
        print(f"   {feature}")
    
    print(f"\nüéâ All {len(features_tested)} required features implemented and tested successfully!")
    
    return True


async def test_performance_characteristics():
    """Test performance characteristics of the streaming system"""
    print("\n" + "=" * 60)
    print("PERFORMANCE CHARACTERISTICS TEST")
    print("=" * 60)
    
    streamer = ProgressiveResponseStreamer(
        buffer_size=2048,
        chunk_size=512,
        max_concurrent_streams=5
    )
    
    # Create large content set
    large_content_set = []
    for i in range(50):
        large_content_set.append(
            ContentSection(
                content=f"Content section {i+1}: " + "This is detailed content. " * 20,
                content_type=ContentType.TEXT,
                priority=Priority.MEDIUM,
                relevance_score=0.5,
                expertise_level=ExpertiseLevel.INTERMEDIATE,
                format_type=FormatType.PLAIN_TEXT,
                estimated_read_time=2.0
            )
        )
    
    print(f"Testing with {len(large_content_set)} content sections...")
    
    start_time = asyncio.get_event_loop().time()
    
    chunk_count = 0
    async for chunk in streamer.stream_priority_content(large_content_set):
        chunk_count += 1
        if chunk_count % 10 == 0:
            print(f"   Processed {chunk_count} chunks...")
    
    end_time = asyncio.get_event_loop().time()
    processing_time = end_time - start_time
    
    print(f"\nüìä Performance Results:")
    print(f"   Total chunks processed: {chunk_count}")
    print(f"   Processing time: {processing_time:.2f} seconds")
    print(f"   Chunks per second: {chunk_count / processing_time:.1f}")
    print(f"   Average time per chunk: {(processing_time / chunk_count) * 1000:.1f} ms")
    
    # Performance should be reasonable
    assert processing_time < 10.0, f"Processing took too long: {processing_time:.2f}s"
    assert chunk_count >= 52, f"Expected at least 52 chunks (metadata + 50 content + completion), got {chunk_count}"
    
    print("   ‚úÖ Performance characteristics acceptable!")
    
    return True


async def main():
    """Run all integration tests"""
    try:
        print("Starting Progressive Response Streaming Integration Tests...")
        
        # Run feature demonstration
        await demonstrate_all_features()
        
        # Run performance test
        await test_performance_characteristics()
        
        print("\n" + "üéâ" * 20)
        print("ALL INTEGRATION TESTS PASSED SUCCESSFULLY!")
        print("Progressive Response Streaming System is fully functional!")
        print("üéâ" * 20)
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)