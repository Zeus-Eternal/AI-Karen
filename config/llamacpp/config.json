{
  "model_path": "./models/llama-cpp/Phi-3-mini-4k-instruct-q4.gguf",
  "host": "127.0.0.1",
  "port": 8080,
  "n_ctx": 4096,
  "n_threads": 8,
  "n_gpu_layers": 0,
  "verbose": true,
  "temperature": 0.7,
  "top_p": 0.9,
  "top_k": 40,
  "timeout": 300,
  "max_retries": 3,
  "health_check_interval": 30,
  "auto_restart": true,
  "auto_restart_delay": 5,
  "memory_threshold_mb": 100,
  "cpu_threshold_percent": 90,
  "server_bin": "/media/zeus/Development7/GitHub/serverKent/serverKent/.bin/llama-server",
  "log_dir": "./logs/llamacpp",
  "model_search_paths": [
    "./models",
    "/models"
  ]
}
