# Memory Architecture


Kari uses a multi-tier memory system to balance speed and recall quality.

1. **NeuroVault** – an in-memory buffer used by `ChatHub` for short-term context. Records decay with `v(t)=v₀ e^{-0.05t}` (days) and can be purged via slash command.
2. **MilvusClient** – an in-process vector store with TTL pruning. It stores embeddings along with metadata such as `timestamp`, `tag` and optional `ttl_override`.
3. **Redis Cache** – a lightweight cache for hot items and recent events. This is currently a stub implementation in memory; the API mirrors Redis commands.
4. **SessionBuffer** – a DuckDB-backed queue that holds chat logs until they can be flushed to Postgres. Flushes occur on session end or when the buffer reaches a configurable size.
5. **Postgres** – relational store for structured logs and plugin state. Used when the engine needs ACID compliance or joins across metadata.
6. **Elasticsearch** – optional full-text index for transcripts and document archives. Provides rich keyword search alongside dense vector recall.

### Storage Responsibilities

- **Dense vectors** → **MilvusClient**
- **Relational data / metadata** → **Postgres**
- **Full-text search** → **Elasticsearch**
- **Hot cache / events** → **Redis Cache**
 

 
Embeddings are generated by `EmbeddingManager`, which deterministically hashes text into a fixed-size vector. When new text is ingested the engine calculates a _surprise_ score based on existing vectors. Low-surprise inputs are ignored to keep the store compact.

### Ingestion

```python
engine.ingest("remember this", {"tag": "demo"}, ttl_seconds=3600)
```

The record is stored with the current timestamp. A background call to `prune()` removes entries older than the TTL or custom override.

### Query

```python
results = engine.query("memory", top_k=5, metadata_filter={"tag": "demo"})
```

Results are ranked by cosine similarity and recency using an exponential decay controlled by `recency_alpha`.

### Decay & Surprise Weighting

- **TTL** determines when records expire.
- **Recency weight** favors newer memories during search.
- **Surprise score** prevents storing data too similar to existing vectors.

This system keeps the memory footprint small while allowing high recall accuracy. See [docs/observability.md](observability.md) for metrics exposed during upsert and search operations.

## ElasticSearch Integration

When ElasticSearch is available the memory manager uses it as the first lookup layer. Configure the connection via environment variables:

- `ELASTIC_HOST` – host of the Elastic cluster (default `localhost`)
- `ELASTIC_PORT` – port of the cluster (default `9200`)
- `ELASTIC_USER` – basic auth user (optional)
- `ELASTIC_PASSWORD` – password for the user (optional)
- `ELASTIC_INDEX` – index name for Kari memory (default `kari_memory`)

If these variables are unset the client falls back to its in-memory stub.

## Session Buffering

Kari's chat runtime stores every user interaction using the `SessionBuffer`
class located at `ai_karen_engine.core.memory.session_buffer`. The buffer
records operations into a local DuckDB file before they are persisted to the
primary Postgres store. This design allows high-throughput logging while
offline and protects against transient database outages.

When `SessionBuffer` is enabled, each chat turn is appended to a DuckDB table.
Periodically a background task flushes these rows in batches to Postgres. The
flush threshold and time interval are controlled via the following environment
variables:

- `SESSION_BUFFER_PATH` – location of the DuckDB file (default
  `session_buffer.duckdb`)
- `SESSION_FLUSH_BATCH` – number of operations to accumulate before flushing
- `SESSION_FLUSH_SECONDS` – maximum seconds between flushes

If Postgres is unreachable, the buffer simply continues writing to DuckDB.
During the next startup `SessionBuffer.replay()` scans any unflushed entries and
replays them to Postgres so no chat history is lost.

