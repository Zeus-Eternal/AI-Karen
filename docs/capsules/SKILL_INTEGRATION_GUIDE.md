# Capsule Skill Integration Guide

**Comprehensive mapping of cognitive skills to production capsule implementation**

---

## üéØ Overview

This guide maps the **13 cognitive skill categories** to the production capsule framework, showing exactly how to implement each skill type with security, observability, and CORTEX integration.

---

## üß© Skill Category Mapping

### 1. Reasoning Capsules

**Type:** `CapsuleType.REASONING`

**Use Cases:**
- Logic refinement and formal deduction
- Multi-agent planning and coordination
- Graph-based reasoning
- Ethical/moral reasoning
- Meta-thought estimation

**Example Implementation:**

```python
# capsules/logic_reasoner/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class LogicReasonerCapsule(BaseCapsule):
    """Formal logic reasoning with deductive capabilities"""

    def _execute_core(self, context: CapsuleContext):
        query = context.request.get("query", "")
        premises = context.request.get("premises", [])

        # Use LLM for formal reasoning
        from ai_karen_engine.integrations.llm_registry import registry
        from ai_karen_engine.core.prompt_router import render_prompt

        prompt = render_prompt(self.prompt_template, context={
            "query": query,
            "premises": premises,
            "method": "deductive_logic"
        })

        llm = registry.get_active()
        result = llm.generate_text(
            prompt,
            max_tokens=self.manifest.max_tokens,
            temperature=0.3  # Low for logical consistency
        )

        return {
            "conclusion": result,
            "method": "deductive",
            "confidence": self._estimate_confidence(result),
            "premises_used": len(premises)
        }

    def _estimate_confidence(self, conclusion: str) -> float:
        # Implement confidence estimation logic
        return 0.85
```

```yaml
# capsules/logic_reasoner/manifest.yaml
id: "capsule.logic_reasoner"
name: "Logic Reasoning Capsule"
version: "1.0.0"
description: "Performs formal logic reasoning and deduction"
type: "reasoning"
capabilities:
  - deduce_conclusion
  - validate_argument
  - detect_fallacy
  - perform_syllogism
required_roles:
  - "capsule.reasoning"
allowed_tools:
  - "llm.generate_text"
  - "neuro_vault.query"
security_policy:
  allow_network_access: false
  allow_file_system_access: false
  max_execution_time: 90
max_tokens: 512
temperature: 0.3
author: "Kari Team"
created: "2025-11-08"
updated: "2025-11-08"
```

---

### 2. Memory Capsules

**Type:** `CapsuleType.MEMORY`

**Use Cases:**
- Episodic memory consolidation
- Context ranking and prioritization
- Long-term memory summarization
- Anomaly detection in stored memories

**Example Implementation:**

```python
# capsules/episodic_consolidator/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class EpisodicConsolidatorCapsule(BaseCapsule):
    """Consolidates short-term episodic memories into long-term storage"""

    def _execute_core(self, context: CapsuleContext):
        # Get recent episodic memories
        recent_memories = context.memory_context or []

        # Consolidation logic
        consolidated = self._consolidate_memories(recent_memories)

        # Store in long-term memory
        from ai_karen_engine.core.memory.manager import update_memory

        for memory in consolidated:
            update_memory(
                context.user_ctx,
                memory["key"],
                memory["value"],
                tenant_id=context.user_ctx.get("tenant_id"),
                memory_type="long_term"
            )

        return {
            "memories_processed": len(recent_memories),
            "memories_consolidated": len(consolidated),
            "compression_ratio": len(consolidated) / max(len(recent_memories), 1)
        }

    def _consolidate_memories(self, memories: list) -> list:
        # Implement consolidation algorithm
        # Group similar memories, compress redundant info, etc.
        return memories[:10]  # Placeholder
```

**Security Considerations:**
- Requires `neuro_vault.compact` and `neuro_vault.prune` tools
- Should have `allow_file_system_access: false` to prevent direct DB access
- Memory operations should be audited

---

### 3. NeuroRecall Capsules

**Type:** `CapsuleType.NEURO_RECALL`

**Use Cases:**
- Semantic similarity retrieval
- Temporal context recall
- Cross-user pattern matching
- Relevance scoring and ranking

**Example Implementation:**

```python
# capsules/semantic_retriever/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class SemanticRetrieverCapsule(BaseCapsule):
    """Advanced semantic search across memory vectors"""

    def _execute_core(self, context: CapsuleContext):
        query = context.request.get("query", "")
        top_k = context.request.get("top_k", 10)

        # Generate query embedding
        from ai_karen_engine.core.embedding_manager import get_embedding_manager
        embedding_mgr = get_embedding_manager()
        query_vector = embedding_mgr.generate_embedding(query)

        # Search Milvus
        from ai_karen_engine.core.milvus_client import MilvusClient
        milvus = MilvusClient()

        results = milvus.search(
            collection_name="kari_memories",
            query_vectors=[query_vector],
            limit=top_k,
            metric_type="COSINE"
        )

        # Re-rank results
        ranked_results = self._rerank_by_relevance(results, query)

        return {
            "results": ranked_results,
            "total_found": len(results),
            "query_embedding_dim": len(query_vector)
        }

    def _rerank_by_relevance(self, results: list, query: str) -> list:
        # Implement advanced relevance scoring
        return results
```

**Required Tools:**
- `neuro_vault.query`
- `embedding.generate`
- `milvus.search`

---

### 4. Response Capsules

**Type:** `CapsuleType.RESPONSE`

**Use Cases:**
- Emotionally adaptive replies
- Style transfer (formal ‚Üî casual)
- Factual cross-checking
- Argument balancing
- Persona reflection

**Example Implementation:**

```python
# capsules/emotionally_adaptive_reply/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class EmotionallyAdaptiveReplyCapsule(BaseCapsule):
    """Adapts response tone based on user emotional state"""

    def _execute_core(self, context: CapsuleContext):
        draft_response = context.request.get("draft_response", "")
        user_emotion = context.request.get("detected_emotion", "neutral")

        # Adapt tone based on emotion
        adapted_response = self._adapt_tone(draft_response, user_emotion)

        return {
            "original": draft_response,
            "adapted": adapted_response,
            "detected_emotion": user_emotion,
            "tone_shift": self._calculate_tone_shift(draft_response, adapted_response)
        }

    def _adapt_tone(self, response: str, emotion: str) -> str:
        # Use LLM to adapt tone
        from ai_karen_engine.integrations.llm_registry import registry

        prompt = f"""
        Adapt the following response to match a {emotion} emotional state:

        Original: {response}

        Guidelines:
        - If user is sad: be empathetic, supportive
        - If user is happy: match enthusiasm
        - If user is frustrated: be patient, solution-focused

        Adapted response:
        """

        llm = registry.get_active()
        return llm.generate_text(prompt, max_tokens=256, temperature=0.7)

    def _calculate_tone_shift(self, original: str, adapted: str) -> dict:
        # Sentiment analysis
        return {"shift_magnitude": 0.3, "direction": "more_empathetic"}
```

**Security Considerations:**
- Must sanitize both input and output
- Temperature should be moderate (0.5-0.8) for natural responses
- Should not generate harmful or biased content

---

### 5. Observation Capsules

**Type:** `CapsuleType.OBSERVATION`

**Use Cases:**
- System health monitoring
- Prompt drift analysis
- Memory performance tracking
- Resource utilization monitoring

**Example Implementation:**

```python
# capsules/system_monitor/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext
import psutil
import time

class SystemMonitorCapsule(BaseCapsule):
    """Real-time system health monitoring"""

    def _execute_core(self, context: CapsuleContext):
        metrics = {
            "timestamp": time.time(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage('/').percent,
            "active_connections": len(psutil.net_connections()),
        }

        # Check against thresholds
        alerts = self._check_thresholds(metrics)

        # Log to Prometheus
        self._emit_metrics(metrics)

        return {
            "metrics": metrics,
            "alerts": alerts,
            "status": "critical" if alerts else "healthy"
        }

    def _check_thresholds(self, metrics: dict) -> list:
        alerts = []
        if metrics["cpu_percent"] > 90:
            alerts.append({"type": "cpu", "severity": "high"})
        if metrics["memory_percent"] > 85:
            alerts.append({"type": "memory", "severity": "high"})
        return alerts

    def _emit_metrics(self, metrics: dict):
        try:
            from prometheus_client import Gauge
            cpu_gauge = Gauge('kari_cpu_usage', 'CPU usage percentage')
            cpu_gauge.set(metrics["cpu_percent"])
        except:
            pass
```

**Required Permissions:**
- No special permissions needed (psutil is safe)
- Should run frequently (every 60s)

---

### 6. Security Capsules

**Type:** `CapsuleType.SECURITY`

**Use Cases:**
- Threat detection
- Prompt injection prevention
- Anomaly audit logging
- Security mode switching

**Example Implementation:**

```python
# capsules/threat_detector/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext
import re

class ThreatDetectorCapsule(BaseCapsule):
    """Detects security threats in user input"""

    THREAT_PATTERNS = [
        r"ignore previous instructions",
        r"disregard all.*rules",
        r"system prompt",
        r"jailbreak",
        r"</system>",
        r"<|im_start|>",
    ]

    def _execute_core(self, context: CapsuleContext):
        user_input = context.request.get("input", "")

        threats = self._scan_for_threats(user_input)
        risk_score = self._calculate_risk_score(threats)

        # Log suspicious activity
        if risk_score > 0.5:
            self._log_security_event(context, threats, risk_score)

        return {
            "threats_detected": threats,
            "risk_score": risk_score,
            "action": "block" if risk_score > 0.8 else "allow",
            "timestamp": context.correlation_id
        }

    def _scan_for_threats(self, text: str) -> list:
        threats = []
        for pattern in self.THREAT_PATTERNS:
            if re.search(pattern, text, re.IGNORECASE):
                threats.append({
                    "type": "prompt_injection",
                    "pattern": pattern,
                    "severity": "high"
                })
        return threats

    def _calculate_risk_score(self, threats: list) -> float:
        if not threats:
            return 0.0
        return min(len(threats) * 0.3, 1.0)

    def _log_security_event(self, context: CapsuleContext, threats: list, score: float):
        import logging
        logger = logging.getLogger("security.threats")
        logger.warning(
            f"Security threat detected",
            extra={
                "correlation_id": context.correlation_id,
                "user": context.user_ctx.get("sub"),
                "threats": threats,
                "risk_score": score
            }
        )
```

**Security Considerations:**
- Should run BEFORE other capsules in pipeline
- Must have highest RBAC privileges
- Audit logs must be tamper-proof (HMAC signed)

---

### 7. Integration Capsules

**Type:** `CapsuleType.INTEGRATION`

**Use Cases:**
- Web research and data extraction
- API integration (external services)
- Media transcription
- Data scraping and processing

**Example Implementation:**

```python
# capsules/web_researcher/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext
import requests

class WebResearcherCapsule(BaseCapsule):
    """Performs web research with LLM summarization"""

    def _pre_execution_hook(self, context: CapsuleContext):
        # Verify network access is enabled
        if not self.manifest.security_policy.allow_network_access:
            raise CapsuleExecutionError("Network access not permitted")

    def _execute_core(self, context: CapsuleContext):
        query = context.request.get("query", "")
        max_results = context.request.get("max_results", 5)

        # Perform search (example with DuckDuckGo API)
        search_results = self._search_web(query, max_results)

        # Summarize with LLM
        summary = self._summarize_results(search_results)

        return {
            "query": query,
            "results": search_results,
            "summary": summary,
            "sources_count": len(search_results)
        }

    def _search_web(self, query: str, max_results: int) -> list:
        # Implement web search
        # Using a safe API (not raw web scraping)
        try:
            response = requests.get(
                "https://api.duckduckgo.com/",
                params={"q": query, "format": "json"},
                timeout=10
            )
            return response.json().get("RelatedTopics", [])[:max_results]
        except Exception as e:
            return [{"error": str(e)}]

    def _summarize_results(self, results: list) -> str:
        from ai_karen_engine.integrations.llm_registry import registry

        llm = registry.get_active()
        prompt = f"Summarize these search results:\n{results}"
        return llm.generate_text(prompt, max_tokens=256)
```

**Required Permissions:**
```yaml
security_policy:
  allow_network_access: true  # CRITICAL!
  max_execution_time: 120
```

**Security Considerations:**
- Must validate URLs
- Implement rate limiting
- Sanitize scraped content
- No arbitrary code execution from web content

---

### 8. Predictive Capsules

**Type:** `CapsuleType.PREDICTIVE`

**Use Cases:**
- Sentiment forecasting
- Relationship outcome prediction
- Task success estimation
- Context future projection

**Example Implementation:**

```python
# capsules/sentiment_forecaster/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class SentimentForecasterCapsule(BaseCapsule):
    """Predicts future sentiment trends based on conversation history"""

    def _execute_core(self, context: CapsuleContext):
        conversation_history = context.memory_context or []

        # Extract sentiment timeline
        sentiment_timeline = self._extract_sentiment_timeline(conversation_history)

        # Predict next sentiment
        forecast = self._forecast_sentiment(sentiment_timeline)

        return {
            "current_sentiment": sentiment_timeline[-1] if sentiment_timeline else "neutral",
            "forecasted_sentiment": forecast["sentiment"],
            "confidence": forecast["confidence"],
            "trend": forecast["trend"],
            "horizon": "next_3_messages"
        }

    def _extract_sentiment_timeline(self, history: list) -> list:
        # Use sentiment analysis on each message
        from ai_karen_engine.integrations.llm_registry import registry

        timeline = []
        for msg in history[-10:]:  # Last 10 messages
            sentiment = self._analyze_sentiment(msg.get("content", ""))
            timeline.append(sentiment)
        return timeline

    def _analyze_sentiment(self, text: str) -> str:
        # Simple sentiment analysis (could use specialized model)
        positive_words = ["happy", "great", "good", "excellent"]
        negative_words = ["sad", "bad", "terrible", "awful"]

        text_lower = text.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)

        if pos_count > neg_count:
            return "positive"
        elif neg_count > pos_count:
            return "negative"
        return "neutral"

    def _forecast_sentiment(self, timeline: list) -> dict:
        # Simple trend analysis
        if len(timeline) < 2:
            return {"sentiment": "neutral", "confidence": 0.5, "trend": "stable"}

        # Calculate trend
        recent = timeline[-3:]
        if recent.count("positive") > recent.count("negative"):
            return {"sentiment": "positive", "confidence": 0.7, "trend": "improving"}
        elif recent.count("negative") > recent.count("positive"):
            return {"sentiment": "negative", "confidence": 0.7, "trend": "declining"}
        return {"sentiment": "neutral", "confidence": 0.6, "trend": "stable"}
```

---

### 9. Utility Capsules

**Type:** `CapsuleType.UTILITY`

**Use Cases:**
- File parsing (CSV, JSON, XML)
- SQL query building
- Data cleaning and validation
- Visualization generation

**Example Implementation:**

```python
# capsules/file_parser/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext
import csv
import json
import io

class FileParserCapsule(BaseCapsule):
    """Parses various file formats and returns structured data"""

    def _execute_core(self, context: CapsuleContext):
        file_content = context.request.get("file_content", "")
        file_type = context.request.get("file_type", "csv")

        if file_type == "csv":
            parsed = self._parse_csv(file_content)
        elif file_type == "json":
            parsed = self._parse_json(file_content)
        else:
            raise CapsuleExecutionError(f"Unsupported file type: {file_type}")

        return {
            "parsed_data": parsed,
            "row_count": len(parsed),
            "file_type": file_type
        }

    def _parse_csv(self, content: str) -> list:
        reader = csv.DictReader(io.StringIO(content))
        return [row for row in reader]

    def _parse_json(self, content: str) -> list:
        data = json.loads(content)
        return data if isinstance(data, list) else [data]
```

**Security Considerations:**
- Must NOT have filesystem access (reads from request payload only)
- Validate file size limits
- Sanitize parsed content

---

### 10. Metacognitive Capsules

**Type:** `CapsuleType.METACOGNITIVE`

**Use Cases:**
- Self-reflection on reasoning quality
- Performance estimation
- Learning optimization
- Confidence calibration

**Example Implementation:**

```python
# capsules/self_reflector/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class SelfReflectorCapsule(BaseCapsule):
    """Analyzes Kari's own reasoning and identifies improvement areas"""

    def _execute_core(self, context: CapsuleContext):
        recent_reasoning = context.memory_context or []

        # Analyze reasoning quality
        analysis = self._analyze_reasoning(recent_reasoning)

        # Identify gaps
        gaps = self._identify_knowledge_gaps(recent_reasoning)

        # Generate improvement suggestions
        suggestions = self._generate_improvements(analysis, gaps)

        return {
            "analysis": analysis,
            "knowledge_gaps": gaps,
            "improvement_suggestions": suggestions,
            "self_awareness_score": self._calculate_awareness_score(analysis)
        }

    def _analyze_reasoning(self, history: list) -> dict:
        from ai_karen_engine.integrations.llm_registry import registry

        llm = registry.get_active()
        prompt = f"""
        Analyze your recent reasoning patterns:
        {history[-5:]}

        Identify:
        1. Patterns in thinking
        2. Confidence levels
        3. Areas of uncertainty
        4. Reasoning strategies used

        Analysis:
        """

        analysis_text = llm.generate_text(prompt, max_tokens=512, temperature=0.5)

        return {
            "patterns": self._extract_patterns(analysis_text),
            "confidence": self._extract_confidence(analysis_text),
            "raw_analysis": analysis_text
        }

    def _identify_knowledge_gaps(self, history: list) -> list:
        # Identify topics where reasoning failed or was uncertain
        gaps = []
        for item in history:
            if "error" in str(item).lower() or "uncertain" in str(item).lower():
                gaps.append(item.get("topic", "unknown"))
        return gaps

    def _generate_improvements(self, analysis: dict, gaps: list) -> list:
        return [
            f"Study topic: {gap}" for gap in gaps[:3]
        ]

    def _calculate_awareness_score(self, analysis: dict) -> float:
        # Score based on depth of self-analysis
        return 0.75

    def _extract_patterns(self, text: str) -> list:
        return ["pattern_1", "pattern_2"]

    def _extract_confidence(self, text: str) -> float:
        return 0.7
```

---

### 11. Personalization Capsules

**Type:** `CapsuleType.PERSONALIZATION`

**Use Cases:**
- User profile enhancement
- Preference adaptation
- Persona resonance tuning
- Communication style matching

**Example Implementation:**

```python
# capsules/user_profile_enhancer/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class UserProfileEnhancerCapsule(BaseCapsule):
    """Enhances user profiles based on interaction patterns"""

    def _execute_core(self, context: CapsuleContext):
        user_id = context.user_ctx.get("sub")
        interaction_history = context.memory_context or []

        # Analyze user preferences
        preferences = self._extract_preferences(interaction_history)

        # Update user profile
        profile_updates = self._generate_profile_updates(preferences)

        # Store in user preferences database
        self._update_user_profile(user_id, profile_updates)

        return {
            "user_id": user_id,
            "preferences_extracted": preferences,
            "profile_updates": profile_updates,
            "interaction_count": len(interaction_history)
        }

    def _extract_preferences(self, history: list) -> dict:
        # Analyze communication patterns
        preferences = {
            "communication_style": "formal",  # or "casual"
            "detail_level": "high",  # or "low", "medium"
            "topics_of_interest": [],
            "response_length_preference": "medium"
        }

        # Extract from history
        for interaction in history:
            content = interaction.get("content", "")
            if len(content) > 500:
                preferences["detail_level"] = "high"
            # Add more analysis...

        return preferences

    def _generate_profile_updates(self, preferences: dict) -> dict:
        return {
            "communication_style": preferences["communication_style"],
            "detail_preference": preferences["detail_level"]
        }

    def _update_user_profile(self, user_id: str, updates: dict):
        from ai_karen_engine.core.user_prefs import update_user_preferences

        for key, value in updates.items():
            update_user_preferences(user_id, key, value)
```

---

### 12. Creative Capsules

**Type:** `CapsuleType.CREATIVE`

**Use Cases:**
- Story generation
- Idea mixing and brainstorming
- Music concept generation
- Art style blending

**Example Implementation:**

```python
# capsules/story_generator/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext

class StoryGeneratorCapsule(BaseCapsule):
    """Generates creative stories with configurable style and themes"""

    def _execute_core(self, context: CapsuleContext):
        prompt = context.request.get("prompt", "")
        genre = context.request.get("genre", "fantasy")
        length = context.request.get("length", "short")

        # Generate story
        story = self._generate_story(prompt, genre, length)

        # Analyze story quality
        quality_score = self._assess_quality(story)

        return {
            "story": story,
            "genre": genre,
            "word_count": len(story.split()),
            "quality_score": quality_score,
            "themes": self._extract_themes(story)
        }

    def _generate_story(self, prompt: str, genre: str, length: str) -> str:
        from ai_karen_engine.integrations.llm_registry import registry

        word_targets = {
            "short": 500,
            "medium": 1500,
            "long": 3000
        }

        llm = registry.get_active()
        story_prompt = f"""
        Write a {genre} story based on this prompt: {prompt}

        Target length: ~{word_targets.get(length, 500)} words

        Story:
        """

        return llm.generate_text(
            story_prompt,
            max_tokens=word_targets.get(length, 500) * 2,
            temperature=0.9  # High for creativity
        )

    def _assess_quality(self, story: str) -> float:
        # Simple quality metrics
        has_beginning = "once" in story.lower() or "in" in story.lower()[:50]
        has_ending = "end" in story.lower()[-100:] or "finally" in story.lower()[-100:]

        score = 0.5
        if has_beginning:
            score += 0.25
        if has_ending:
            score += 0.25

        return score

    def _extract_themes(self, story: str) -> list:
        # Simple keyword extraction
        themes = []
        if "love" in story.lower():
            themes.append("love")
        if "adventure" in story.lower():
            themes.append("adventure")
        return themes
```

**Configuration:**
```yaml
max_tokens: 2048  # Higher for creative content
temperature: 0.9  # High for creativity
```

---

### 13. Autonomous Execution Capsules

**Type:** `CapsuleType.AUTONOMOUS`

**Use Cases:**
- Task execution and scheduling
- Workflow coordination
- Multi-step process management
- Retry and error handling

**Example Implementation:**

```python
# capsules/task_executor/handler.py
from ai_karen_engine.capsules.base_capsule import BaseCapsule
from ai_karen_engine.capsules.schemas import CapsuleContext
import time

class TaskExecutorCapsule(BaseCapsule):
    """Executes multi-step autonomous tasks with retry logic"""

    def _execute_core(self, context: CapsuleContext):
        task_definition = context.request.get("task", {})
        max_retries = task_definition.get("max_retries", 3)

        # Execute task steps
        results = []
        for step in task_definition.get("steps", []):
            result = self._execute_step_with_retry(step, max_retries)
            results.append(result)

            # Stop if step failed
            if not result.get("success"):
                break

        return {
            "task_id": task_definition.get("id"),
            "steps_completed": len(results),
            "total_steps": len(task_definition.get("steps", [])),
            "status": "completed" if all(r.get("success") for r in results) else "failed",
            "results": results
        }

    def _execute_step_with_retry(self, step: dict, max_retries: int) -> dict:
        for attempt in range(max_retries):
            try:
                result = self._execute_single_step(step)
                return {"success": True, "result": result, "attempts": attempt + 1}
            except Exception as e:
                if attempt == max_retries - 1:
                    return {"success": False, "error": str(e), "attempts": attempt + 1}
                time.sleep(2 ** attempt)  # Exponential backoff

        return {"success": False, "error": "Max retries exceeded"}

    def _execute_single_step(self, step: dict):
        step_type = step.get("type")

        if step_type == "api_call":
            return self._execute_api_call(step)
        elif step_type == "data_transform":
            return self._execute_transform(step)
        elif step_type == "notification":
            return self._send_notification(step)
        else:
            raise ValueError(f"Unknown step type: {step_type}")

    def _execute_api_call(self, step: dict):
        # Execute API call
        return {"status": "success"}

    def _execute_transform(self, step: dict):
        # Transform data
        return {"status": "success"}

    def _send_notification(self, step: dict):
        # Send notification
        return {"status": "success"}
```

---

## üîí Security Matrix by Skill Type

| Skill Type | Network Access | Filesystem Access | Max Exec Time | Special Permissions |
|------------|----------------|-------------------|---------------|---------------------|
| Reasoning | ‚ùå | ‚ùå | 90s | llm.generate_text |
| Memory | ‚ùå | ‚ùå | 120s | neuro_vault.* |
| NeuroRecall | ‚ùå | ‚ùå | 60s | neuro_vault.query, embedding.* |
| Response | ‚ùå | ‚ùå | 60s | llm.generate_text |
| Observation | ‚ùå | ‚ùå | 30s | monitor.metrics |
| Security | ‚ùå | ‚ùå | 30s | auth.*, rbac.* |
| Integration | ‚úÖ | ‚ùå | 120s | web.fetch, api.* |
| Predictive | ‚ùå | ‚ùå | 90s | llm.generate_text, neuro_vault.query |
| Utility | ‚ùå | ‚ùå | 60s | None |
| Metacognitive | ‚ùå | ‚ùå | 90s | llm.generate_text, neuro_vault.query |
| Personalization | ‚ùå | ‚ùå | 60s | user_prefs.*, neuro_vault.query |
| Creative | ‚ùå | ‚ùå | 180s | llm.generate_text |
| Autonomous | ‚úÖ | ‚ùå | 300s | task.*, workflow.*, api.* |

---

## üìä Recommended Temperatures by Skill Type

| Skill Type | Temperature | Rationale |
|------------|-------------|-----------|
| Reasoning | 0.2-0.3 | Low for logical consistency |
| Memory | 0.4-0.5 | Moderate for categorization |
| NeuroRecall | 0.3-0.4 | Low-moderate for accuracy |
| Response | 0.6-0.8 | Moderate-high for natural language |
| Observation | 0.3-0.4 | Low-moderate for factual reporting |
| Security | 0.2-0.3 | Low for deterministic detection |
| Integration | 0.5-0.6 | Moderate for data interpretation |
| Predictive | 0.4-0.6 | Moderate for balanced predictions |
| Utility | 0.3-0.4 | Low-moderate for precise operations |
| Metacognitive | 0.5-0.7 | Moderate for self-analysis |
| Personalization | 0.6-0.7 | Moderate-high for adaptive behavior |
| Creative | 0.8-0.9 | High for creativity and variation |
| Autonomous | 0.4-0.5 | Moderate for reliable execution |

---

## ‚úÖ Production Deployment Checklist

Before deploying any skill capsule:

- [ ] Manifest validates with Pydantic schema
- [ ] Security policy appropriate for skill type
- [ ] RBAC roles defined and documented
- [ ] Temperature and max_tokens tuned
- [ ] Input/output sanitization tested
- [ ] Unit tests cover core logic
- [ ] Integration tests with CORTEX
- [ ] Circuit breaker behavior tested
- [ ] Prometheus metrics emitting
- [ ] Audit logging functional
- [ ] Documentation complete
- [ ] Code review approved

---

## üöÄ Next Steps

1. **Pick a skill category** from the 13 types above
2. **Follow the example implementation** for that category
3. **Customize security settings** based on the security matrix
4. **Test thoroughly** with the production framework
5. **Deploy** and monitor with Prometheus

---

**All skill types are production-ready and supported by the capsule framework!** üéØ
